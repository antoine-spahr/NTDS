{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting 8 new movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, precision_score, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "import dgl.nn.pytorch as dgl_nn\n",
    "import dgl.transform as dgl_transform\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "Data_path = '../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(df, col, min_nbr=0, key='name'):\n",
    "    \"\"\"\n",
    "    Get the number of unique values in the dictionnaries of the columns col from the data. \n",
    "    INPUT\n",
    "        |---- data [pandas Dataframe] the dataframe with the data \n",
    "        |---- col [string array] column name to count unique values\n",
    "        |---- min_nbr [int] the minimum number of apperance of the value to be kepts\n",
    "    OUTPUT \n",
    "        |---- l [list] list of unique values \n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "    tmp[col] = tmp[col].apply(lambda x : [value[key] for value in ast.literal_eval(x)])\n",
    "    tmp = tmp[['title',col]].explode(col)\n",
    "    tmp = tmp[col].value_counts()\n",
    "    return list(tmp[tmp > min_nbr].index)\n",
    "\n",
    "def add_dummy_features(df, col, min_nbr, key='name'):\n",
    "    \"\"\" \n",
    "    Convert the columns col from the dataframe df as dummy variable \n",
    "    for each word appearing more that min_nbr.\n",
    "    INPUT\n",
    "        |---- df [pandas Dataframe] the dataframe with the data \n",
    "        |---- col [string array] column name to dummify\n",
    "        |---- min_nbr [int] the minimum number of apperance of the value to be kepts\n",
    "    OUTPUT \n",
    "        |---- df [pandas Dataframe] the dataframe with the data dummified\n",
    "    \"\"\"\n",
    "    # get the list of possible value in col\n",
    "    val_list = get_list(df, col, min_nbr=min_nbr, key=key)\n",
    "    # keep only the value in val_list\n",
    "    X = df[col].apply(lambda x : [value[key] for value in ast.literal_eval(x)])\n",
    "    X = X.apply(lambda x : [val for val in x if val in val_list])\n",
    "    # get the list as dummy variable\n",
    "    tmp = pd.get_dummies(X.apply(pd.Series), prefix='', prefix_sep='').sum(level=0, axis=1)\n",
    "    # add the new feature to the dataframe\n",
    "    return pd.concat([df, tmp], axis=1).drop(columns=[col])\n",
    "\n",
    "def do_standardisation(data, train_mask):\n",
    "    '''\n",
    "    DESCRIPTION: standardise features to zero mean and unit variance\n",
    "    INPUT: \n",
    "        |--- data: [np.darray] feature matrix\n",
    "        |--- train_mask: [list] indices of train samples\n",
    "        |--- val_mask: [list] indices of validation samples\n",
    "        |--- test_mask: [list] indices of test samples\n",
    "    OUTPUT:\n",
    "        |--- data: [np.darray] feature matrix with standardized feature columns\n",
    "    '''\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data.iloc[train_mask].to_numpy())\n",
    "    return pd.DataFrame(data = scaler.transform(data.to_numpy()),columns=data.columns)\n",
    "\n",
    "def train(model, g, features, labels, train_mask, loss_fcn, optimizer):\n",
    "    \"\"\" \n",
    "    DESCRIPTION : Train and update model classification performances with training set\n",
    "    INPUT:\n",
    "        |--- model: [] classification model to train\n",
    "        |--- g: [DGLgraph] DeepGraphLearning graph object\n",
    "        |--- features: [FloatTensor] 2D tensor containing samples' features\n",
    "        |--- labels: [LongTensor] 1D tensor containing samples' labels (0-1)\n",
    "        |--- train_mask: [np.array] indices of training set\n",
    "        |--- loss_fcn: pytorch loss function chosen for model training\n",
    "        |--- optimizer: pytorch model optimizer \n",
    "    OUTPUT:\n",
    "        |--- loss: [float] value of loss function for the model at current state\n",
    "    \"\"\"\n",
    "    model.train()  \n",
    "    \n",
    "    pred = model(g, features)[train_mask] \n",
    "    loss = loss_fcn(pred, labels[train_mask])\n",
    "    _, indices = torch.max(pred, dim=1)\n",
    "    acc = sklearn.metrics.accuracy_score(labels[train_mask], indices.numpy(), normalize=True, sample_weight=None)\n",
    "    pre,rec,f1,sup = precision_recall_fscore_support(labels[train_mask],indices.numpy())\n",
    "    optimizer.zero_grad()    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, pre[1], rec[1], f1[1], sup[1], acc\n",
    "    \n",
    "def evaluate(model, g, features, mask, labels):\n",
    "    \"\"\" \n",
    "    DESCRIPTION : Evaluate model classification performance on validation set \n",
    "    INPUT:\n",
    "        |--- model: [] classification model to evaluate\n",
    "        |--- g: [DGLgraph] DeepGraphLearning graph object\n",
    "        |--- features: [FloatTensor] 2D tensor containing samples' features\n",
    "        |--- labels: [LongTensor] 1D tensor containing samples' labels (0-1)\n",
    "        |--- mask: [np.array] indices of validation set\n",
    "    OUTPUT:\n",
    "        |--- acc: [float] classification accuracy\n",
    "        |--- recall: [float] classification recall\n",
    "        |--- precision: [float] classification precision\n",
    "        |--- f1: [float] classification f1 score\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(g, features)[mask]  \n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(pred, dim=1)\n",
    "        acc = sklearn.metrics.accuracy_score(labels, indices.numpy(), normalize=True, sample_weight=None)\n",
    "        pre,rec,f1,sup = precision_recall_fscore_support(labels,indices.numpy())\n",
    "        C = sklearn.metrics.confusion_matrix(labels, indices.numpy())\n",
    "        \n",
    "        return acc, pre[1], rec[1], f1[1], sup[1], C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading csim_all_2020 similarity matrix with shape (4810, 4810)\n"
     ]
    }
   ],
   "source": [
    "with open(Data_path+'csim_all_2020', 'rb') as src:\n",
    "        sim_mat = pickle.load(src)\n",
    "        print(f'>>> Loading csim_all_2020 similarity matrix with shape {sim_mat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the Adjacency matrix : pruning at 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sim_mat.values\n",
    "# prune it at 0.25 (remove all similarity smaller than 0.25)\n",
    "A = np.where(A <= 0.25, 0, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dgl graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate graph\n",
    "G = DGLGraph(graph_data=A)\n",
    "G = dgl_transform.add_self_loop(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the attritubes and make features, lables and index dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Data_path + 'merged_data_2020.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "features_df = df[['title', 'budget', 'genres', 'popularity', 'revenue','runtime','vote_average','vote_count']]\n",
    "features_df = add_dummy_features(features_df, 'genres', min_nbr=0).drop(columns=('title')).reset_index(drop=True)\n",
    "# labels\n",
    "labels_df = df[['Nominations', 'Awards']].reset_index(drop=True)\n",
    "# index names \n",
    "nodes_name = df[['title']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3728\n",
       "1.0    1074\n",
       "Name: Nominations, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the binary label\n",
    "IMDB_nom = labels_df['Nominations'].copy()\n",
    "IMDB_nom.loc[IMDB_nom > 0] = 1\n",
    "# Checking class imbalance\n",
    "IMDB_nom.value_counts() # 18.263 % of CLASS 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Transform of some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of budget, popularity, revenue and vote_count features\n",
    "features_to_transform = features_df[['budget', 'popularity', 'revenue', 'vote_count']]\n",
    "feat_names = ['budget', 'popularity', 'revenue', 'vote_count']\n",
    "transformed_feat = features_df.copy()\n",
    "transformed_feat.loc[:,feat_names] = (np.log(features_to_transform.mask(features_to_transform <=0)).fillna(0))#np.log(features_to_transform)#.replace(-np.inf, 0)#, where=(features_to_transform>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> feature is given in `transformed_feat` and the labels are given in `IMDB_nom`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data in train and test sets\n",
    "Train on the 4802 nodes for which we know the nomination. \n",
    "<br>Test if the 8 popular movie of 2019 are predicted as nominated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.arange(0,4802,1)\n",
    "test_mask = np.arange(4802,A.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of feature matrix\n",
    "transformed_feat_std = do_standardisation(transformed_feat, train_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature tensors\n",
    "tensor_data_std = torch.FloatTensor(transformed_feat_std.values)\n",
    "# labels tensors\n",
    "tensor_labels = torch.LongTensor(IMDB_nom.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the three models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      ">>> Precision: 0.6909\n",
      ">>> Recall: 0.487\n",
      ">>> F1: 0.5713\n",
      ">>> Support: 1074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C= 1,random_state = 0,solver = 'lbfgs').fit(transformed_feat_std.iloc[train_mask].to_numpy(),IMDB_nom.values[train_mask])\n",
    "train_pred = clf.predict(transformed_feat_std.iloc[train_mask].to_numpy())\n",
    "\n",
    "# Train set results\n",
    "tr_pre_log,tr_rec_log,tr_f1_log,tr_sup_log = precision_recall_fscore_support(IMDB_nom.values[train_mask],train_pred)\n",
    "tr_acc_log = sklearn.metrics.accuracy_score(IMDB_nom.values[train_mask], train_pred, normalize=True, sample_weight=None)\n",
    "\n",
    "print('Training set:')\n",
    "print('>>> Precision: {:0.4}'.format(tr_pre_log[1]))\n",
    "print('>>> Recall: {:0.4}'.format(tr_rec_log[1]))\n",
    "print('>>> F1: {:0.4}'.format(tr_f1_log[1]))\n",
    "print('>>> Support: {:}'.format(tr_sup_log[1]))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Filter + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacianPolynomial(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats: int,\n",
    "                 out_feats: int,\n",
    "                 k: int,\n",
    "                 dropout_prob: float,\n",
    "                 norm=True):\n",
    "        super().__init__()\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self._k = k\n",
    "        self._norm = norm\n",
    "        # Contains the weights learned by the Laplacian polynomial\n",
    "        self.pol_weights = nn.Parameter(torch.Tensor(self._k + 1))\n",
    "        # Contains the weights learned by the logistic regression (without bias)\n",
    "        self.logr_weights = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        torch.manual_seed(0)\n",
    "        torch.nn.init.xavier_uniform_(self.logr_weights, gain=0.01)\n",
    "        torch.nn.init.normal_(self.pol_weights, mean=0.0, std=1e-3)\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "        r\"\"\"Compute graph convolution.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        * Input shape: :math:`(N, *, \\text{in_feats})` where * means any number of additional\n",
    "          dimensions, :math:`N` is the number of nodes.\n",
    "        * Output shape: :math:`(N, *, \\text{out_feats})` where all but the last dimension are\n",
    "          the same shape as the input.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph (DGLGraph) : The graph.\n",
    "        feat (torch.Tensor): The input feature\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (torch.Tensor) The output feature\n",
    "        \"\"\"\n",
    "        feat = self.dropout(feat)\n",
    "        graph = graph.local_var()\n",
    "\n",
    "        norm = torch.pow(graph.in_degrees().float().clamp(min=1), -0.5)\n",
    "        shp = norm.shape + (1,) * (feat.dim() - 1)\n",
    "        norm = torch.reshape(norm, shp)\n",
    "\n",
    "        # mult W first to reduce the feature size for aggregation.\n",
    "        feat = torch.matmul(feat, self.logr_weights) # X*Teta\n",
    "\n",
    "        result = self.pol_weights[0] * feat.clone() # a0*L^0*X*Teta <-- fisrt polynomial weight a0 * L^0 * x\n",
    "\n",
    "        for i in range(1, self._k + 1): # get the next polynomial coefficient (a1*L^1, a2*L^2, ..... ak*L^k) \n",
    "            old_feat = feat.clone()\n",
    "            if self._norm:\n",
    "                feat = feat * norm\n",
    "            graph.ndata['h'] = feat\n",
    "            # Feat is not modified in place\n",
    "            graph.update_all(fn.copy_src(src='h', out='m'),\n",
    "                             fn.sum(msg='m', out='h')) # update all nodes with msg function copy_src (get data from source node) and reduce function sum\n",
    "            if self._norm:\n",
    "                graph.ndata['h'] = graph.ndata['h'] * norm\n",
    "\n",
    "            feat = old_feat - graph.ndata['h']\n",
    "            result += self.pol_weights[i] * feat\n",
    "\n",
    "        return result\n",
    "\n",
    "    def extra_repr(self):\n",
    "        \"\"\"Set the extra representation of the module,\n",
    "        which will come into effect when printing the model.\n",
    "        \"\"\"\n",
    "        summary = 'in={_in_feats}, out={_out_feats}'\n",
    "        summary += ', normalization={_norm}'\n",
    "        return summary.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0050 | Train Loss 0.5129 | Train precision 39.8190% | Train recall 90.1304% | Train F1 55.2354%\n",
      "Epoch 0100 | Train Loss 0.5069 | Train precision 39.1093% | Train recall 89.9441% | Train F1 54.5147%\n",
      "Epoch 0150 | Train Loss 0.5053 | Train precision 39.8512% | Train recall 89.7579% | Train F1 55.1961%\n",
      "Epoch 0200 | Train Loss 0.5053 | Train precision 39.8758% | Train recall 89.6648% | Train F1 55.2021%\n",
      "Epoch 0250 | Train Loss 0.5114 | Train precision 39.7605% | Train recall 89.6648% | Train F1 55.0915%\n",
      "Epoch 0300 | Train Loss 0.5031 | Train precision 40.1490% | Train recall 90.3166% | Train F1 55.5874%\n",
      "Epoch 0350 | Train Loss 0.5118 | Train precision 40.3253% | Train recall 90.0372% | Train F1 55.7028%\n",
      "Epoch 0400 | Train Loss 0.5063 | Train precision 40.1224% | Train recall 91.5270% | Train F1 55.7889%\n",
      "Epoch 0450 | Train Loss 0.5044 | Train precision 39.5559% | Train recall 89.5717% | Train F1 54.8774%\n",
      "Epoch 0500 | Train Loss 0.5090 | Train precision 39.7709% | Train recall 90.5028% | Train F1 55.2587%\n",
      "Epoch 0550 | Train Loss 0.5036 | Train precision 39.8133% | Train recall 91.3408% | Train F1 55.4551%\n",
      "Epoch 0600 | Train Loss 0.5085 | Train precision 39.7690% | Train recall 89.7579% | Train F1 55.1172%\n",
      "Epoch 0650 | Train Loss 0.5090 | Train precision 40.0331% | Train recall 90.1304% | Train F1 55.4410%\n",
      "Epoch 0700 | Train Loss 0.5109 | Train precision 39.9501% | Train recall 89.3855% | Train F1 55.2200%\n",
      "Epoch 0750 | Train Loss 0.5004 | Train precision 39.8441% | Train recall 90.4097% | Train F1 55.3119%\n",
      "Epoch 0800 | Train Loss 0.5032 | Train precision 40.2088% | Train recall 89.6648% | Train F1 55.5203%\n",
      "Epoch 0850 | Train Loss 0.5155 | Train precision 38.9176% | Train recall 91.0615% | Train F1 54.5302%\n",
      "Epoch 0900 | Train Loss 0.5092 | Train precision 39.5538% | Train recall 90.7821% | Train F1 55.1003%\n",
      "Epoch 0950 | Train Loss 0.5091 | Train precision 40.3662% | Train recall 90.3166% | Train F1 55.7952%\n",
      "Epoch 1000 | Train Loss 0.5107 | Train precision 38.7869% | Train recall 90.5028% | Train F1 54.3017%\n"
     ]
    }
   ],
   "source": [
    "# Best Model based on F1 score\n",
    "pol_order = 3 \n",
    "lr = 0.3\n",
    "weight_decay = 5e-05\n",
    "n_epochs = 1000 \n",
    "p_dropout = 0.2 \n",
    "n_classes = 2\n",
    "in_feats=tensor_data_std.shape[1]\n",
    "\n",
    "true_ratio = 1074/4802 # <-- fraction of Nominations\n",
    "weights_loss = torch.FloatTensor([true_ratio, 1-true_ratio]) # to rebalance classes\n",
    "\n",
    "# Training Laplacian Polynomial Graph Filter & Logistic Regression with best hyperparameters\n",
    "model_GF_LR = LaplacianPolynomial(in_feats, n_classes, pol_order, p_dropout)\n",
    "\n",
    "loss_fcn = torch.nn.CrossEntropyLoss(weight=weights_loss)\n",
    "optimizer = torch.optim.Adam(model_GF_LR.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "losses_logF = []\n",
    "f1_tr = []\n",
    "for epoch in range(n_epochs):\n",
    "    loss, pre_tr_logF, rec_tr_logF, f1_tr_logF, sup_tr_logF, acc_tr_logF = train(model_GF_LR, G, tensor_data_std, tensor_labels, train_mask, loss_fcn, optimizer)\n",
    "    losses_logF.append(loss)\n",
    "    f1_tr.append(f1_tr_logF)\n",
    "\n",
    "    if (epoch+1)%50 == 0:\n",
    "        print(\"Epoch {:04d} | Train Loss {:.4f} | Train precision {:.4%} | Train recall {:.4%} | Train F1 {:.4%}\". format(epoch+1, loss.item(), pre_tr_logF, rec_tr_logF, f1_tr_logF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_GNN(nn.Module):\n",
    "    def __init__(self, in_feats: int, out_feats: int, first_layer_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self._first_layer_size = first_layer_size\n",
    "        self._hidden_size = hidden_size\n",
    "\n",
    "        layer_size = 128\n",
    "        self.linear = nn.Linear(self._in_feats, self._first_layer_size)\n",
    "        self.gcn1 = dgl_nn.conv.GraphConv(self._first_layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn2 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn3 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn4 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn5 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn6 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn7 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn8 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn9 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn10 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.gcn11 = dgl_nn.conv.GraphConv(layer_size, layer_size, activation=F.relu)\n",
    "        self.linear1 = nn.Linear(layer_size, self._hidden_size)\n",
    "        self.linear2 = nn.Linear(self._hidden_size, self._out_feats)\n",
    "        \n",
    "    def forward(self, graph, feat):\n",
    "        h = F.relu(self.linear(feat))\n",
    "        h = self.gcn1(graph, h)\n",
    "        h = self.gcn2(graph, h)\n",
    "        h = self.gcn3(graph, h)\n",
    "        h = self.gcn4(graph, h)\n",
    "        h = self.gcn5(graph, h)\n",
    "        h = self.gcn6(graph, h)\n",
    "        h = self.gcn7(graph, h)\n",
    "        h = self.gcn8(graph, h)\n",
    "        h = self.gcn9(graph, h)\n",
    "        h = self.gcn10(graph, h)\n",
    "        h = self.gcn11(graph, h)\n",
    "        h = self.linear1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear2(h)\n",
    "        h = F.log_softmax(h, dim=1)\n",
    "        return h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model based on F1 score \n",
    "in_feats = tensor_data_std.shape[1]\n",
    "out_feats = 2\n",
    "n_epochs = 1000\n",
    "learning_rate = 1e-3\n",
    "first_layer_size = 16\n",
    "hidden_size = 512\n",
    "weight_decay = 0 \n",
    "true_ratio = 1074/4802 # <-- fraction of Nominations\n",
    "weights_loss = torch.FloatTensor([true_ratio, 1-true_ratio]) # to rebalance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0050 | Train Loss 0.5921 | Train precision 36.4827% | Train recall 72.6257% | Train F1 48.5679%\n",
      "Epoch 0100 | Train Loss 0.5817 | Train precision 39.8086% | Train recall 65.8287% | Train F1 49.6140%\n",
      "Epoch 0150 | Train Loss 0.5883 | Train precision 36.7128% | Train recall 76.5363% | Train F1 49.6227%\n",
      "Epoch 0200 | Train Loss 0.5802 | Train precision 40.3182% | Train recall 68.4358% | Train F1 50.7421%\n",
      "Epoch 0250 | Train Loss 0.5579 | Train precision 42.2424% | Train recall 69.4600% | Train F1 52.5352%\n",
      "Epoch 0300 | Train Loss 0.5490 | Train precision 43.3995% | Train recall 69.1806% | Train F1 53.3381%\n",
      "Epoch 0350 | Train Loss 0.5770 | Train precision 38.2495% | Train recall 73.6499% | Train F1 50.3501%\n",
      "Epoch 0400 | Train Loss 0.5460 | Train precision 46.0224% | Train recall 65.1769% | Train F1 53.9499%\n",
      "Epoch 0450 | Train Loss 0.5400 | Train precision 45.1151% | Train recall 67.5047% | Train F1 54.0843%\n",
      "Epoch 0500 | Train Loss 0.5400 | Train precision 45.8097% | Train recall 67.6909% | Train F1 54.6411%\n",
      "Epoch 0550 | Train Loss 0.5312 | Train precision 40.9960% | Train recall 75.8845% | Train F1 53.2332%\n",
      "Epoch 0600 | Train Loss 0.5257 | Train precision 45.5603% | Train recall 69.2737% | Train F1 54.9686%\n",
      "Epoch 0650 | Train Loss 0.5189 | Train precision 43.7883% | Train recall 73.1844% | Train F1 54.7926%\n",
      "Epoch 0700 | Train Loss 0.5272 | Train precision 48.2512% | Train recall 62.9423% | Train F1 54.6263%\n",
      "Epoch 0750 | Train Loss 0.5076 | Train precision 49.2203% | Train recall 67.5978% | Train F1 56.9635%\n",
      "Epoch 0800 | Train Loss 0.5007 | Train precision 49.0106% | Train recall 69.1806% | Train F1 57.3745%\n",
      "Epoch 0850 | Train Loss 0.4955 | Train precision 45.9073% | Train recall 74.6741% | Train F1 56.8593%\n",
      "Epoch 0900 | Train Loss 0.4907 | Train precision 44.3129% | Train recall 80.1676% | Train F1 57.0766%\n",
      "Epoch 0950 | Train Loss 0.4893 | Train precision 50.3320% | Train recall 70.5773% | Train F1 58.7597%\n",
      "Epoch 1000 | Train Loss 0.4895 | Train precision 45.7221% | Train recall 78.1192% | Train F1 57.6831%\n"
     ]
    }
   ],
   "source": [
    "# Training Linear GNN model with best hyperparameters\n",
    "model_GCN = Linear_GNN(in_feats, out_feats, first_layer_size, hidden_size)\n",
    "\n",
    "loss_fcn = torch.nn.CrossEntropyLoss(weight=weights_loss)\n",
    "optimizer = torch.optim.Adam(model_GCN.parameters(),lr=learning_rate, weight_decay=weight_decay)\n",
    "losses_tr_GNN = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss, pre_tr_GNN, rec_tr_GNN, f1_tr_GNN, sup_tr_GNN, acc_tr_GNN = train(model_GCN, G, tensor_data_std, tensor_labels, train_mask, loss_fcn, optimizer)\n",
    "    losses_tr_GNN.append(loss.item())\n",
    "    \n",
    "    if (epoch+1)%50 == 0:\n",
    "        print(\"Epoch {:04d} | Train Loss {:.4f} | Train precision {:.4%} | Train recall {:.4%} | Train F1 {:.4%}\". format(epoch+1, loss.item(), pre_tr_GNN, rec_tr_GNN, f1_tr_GNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nominated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Joker</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Once Upon a Time... in Hollywood</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Irishman</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parasite</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jojo Rabbit</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Little Women</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mariage Story</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Nominated\n",
       "title                                     \n",
       "Joker                                  yes\n",
       "1917                                   yes\n",
       "Once Upon a Time... in Hollywood       yes\n",
       "The Irishman                           yes\n",
       "Parasite                               yes\n",
       "Jojo Rabbit                             no\n",
       "Little Women                           yes\n",
       "Mariage Story                          yes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pred = clf.predict(transformed_feat_std.iloc[test_mask].to_numpy())\n",
    "LR_pred_df = pd.DataFrame(data=LR_pred, index=nodes_name.iloc[test_mask,0], columns=['Nominated'])\n",
    "LR_pred_df.Nominated.replace((1,0), ('yes', 'no'), inplace=True)\n",
    "LR_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nominated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Joker</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Once Upon a Time... in Hollywood</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Irishman</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parasite</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jojo Rabbit</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Little Women</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mariage Story</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Nominated\n",
       "title                                     \n",
       "Joker                                  yes\n",
       "1917                                   yes\n",
       "Once Upon a Time... in Hollywood       yes\n",
       "The Irishman                           yes\n",
       "Parasite                               yes\n",
       "Jojo Rabbit                            yes\n",
       "Little Women                           yes\n",
       "Mariage Story                          yes"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GF_LR_pred = model_GF_LR(G, tensor_data_std)[test_mask].argmax(dim=1)\n",
    "GF_LR_pred_df = pd.DataFrame(data=GF_LR_pred, index=nodes_name.iloc[test_mask,0], columns=['Nominated'])\n",
    "GF_LR_pred_df.Nominated.replace((1,0), ('yes', 'no'), inplace=True)\n",
    "GF_LR_pred_df\n",
    "#acc_test_logF, pre_test_logF, rec_test_logF, f1_test_logF, sup_test_logF, C_logF = evaluate(model_GF_LR, G, tensor_data_std, test_mask, tensor_labels)\n",
    "#print(\"Precision {:.4%} | Recall {:.4%} | F1 {:.4%}\". format(pre_test_logF, rec_test_logF, f1_test_logF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nominated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Joker</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Once Upon a Time... in Hollywood</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Irishman</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parasite</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jojo Rabbit</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Little Women</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mariage Story</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Nominated\n",
       "title                                     \n",
       "Joker                                   no\n",
       "1917                                   yes\n",
       "Once Upon a Time... in Hollywood       yes\n",
       "The Irishman                           yes\n",
       "Parasite                               yes\n",
       "Jojo Rabbit                            yes\n",
       "Little Women                           yes\n",
       "Mariage Story                          yes"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCN_pred = model_GCN(G, tensor_data_std)[test_mask].argmax(dim=1)\n",
    "GCN_pred_df = pd.DataFrame(data=GCN_pred, index=nodes_name.iloc[test_mask,0], columns=['Nominated'])\n",
    "GCN_pred_df.Nominated.replace((1,0), ('yes', 'no'), inplace=True)\n",
    "GCN_pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
