{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the similarity matrices and the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading keywords similarity matrix with shape (4803, 4803)\n",
      ">>> Loading genre similarity matrix with shape (4803, 4803)\n",
      ">>> Loading crew similarity matrix with shape (4803, 4803)\n",
      ">>> Loading cast similarity matrix with shape (4803, 4803)\n"
     ]
    }
   ],
   "source": [
    "Data_path = 'Data/'\n",
    "\n",
    "sim_mat = {}\n",
    "names = ['keywords', 'genre', 'crew', 'cast']\n",
    "for name in names:\n",
    "    with open(Data_path+'csim_'+name, 'rb') as src:\n",
    "        sim_mat[name] = pickle.load(src)\n",
    "        print(f'>>> Loading {name} similarity matrix with shape {sim_mat[name].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 1** Combine the 4 similarity matrices equitably (**to be optimized**) and pruned those with a similarity below 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple way\n",
    "adj_mat = np.zeros(sim_mat['keywords'].shape)\n",
    "for wi, name in zip([0.25, 0.25, 0.25, 0.25], names):\n",
    "     adj_mat += wi*sim_mat[name].values\n",
    "final_adjacency_mat = adj_mat#np.where(adj_mat < 0.25, 0, adj_mat)\n",
    "weight_dict = {'names':names, 'weights':[0.25, 0.25, 0.25, 0.25]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 2** Grid search the best combination of weights (weights that sum up to 1) and then prune the adjacency matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Combination n°1 with weights (0.0, 0.0, 0.0, 1.0)\n",
      "\t--> Clustering coefficient : 0.026303635985085085 \\ \n",
      "\t--> Giant component size : 16\n",
      ">>> Combination n°2 with weights (0.0, 0.0, 0.125, 0.875)\n",
      "\t--> Clustering coefficient : 0.027978049433389853 \\ \n",
      "\t--> Giant component size : 15\n",
      ">>> Combination n°3 with weights (0.0, 0.0, 0.25, 0.75)\n",
      "\t--> Clustering coefficient : 0.03168786704077149 \\ \n",
      "\t--> Giant component size : 11\n",
      ">>> Combination n°4 with weights (0.0, 0.0, 0.375, 0.625)\n",
      "\t--> Clustering coefficient : 0.04845053851924557 \\ \n",
      "\t--> Giant component size : 15\n",
      ">>> Combination n°5 with weights (0.0, 0.0, 0.5, 0.5)\n",
      "\t--> Clustering coefficient : 0.07188841070789852 \\ \n",
      "\t--> Giant component size : 19\n",
      ">>> Combination n°6 with weights (0.0, 0.0, 0.625, 0.375)\n",
      "\t--> Clustering coefficient : 0.09530091903608456 \\ \n",
      "\t--> Giant component size : 21\n",
      ">>> Combination n°7 with weights (0.0, 0.0, 0.75, 0.25)\n",
      "\t--> Clustering coefficient : 0.1159942300442722 \\ \n",
      "\t--> Giant component size : 28\n",
      ">>> Combination n°8 with weights (0.0, 0.0, 0.875, 0.125)\n",
      "\t--> Clustering coefficient : 0.14289316320950973 \\ \n",
      "\t--> Giant component size : 42\n",
      ">>> Combination n°9 with weights (0.0, 0.0, 1.0, 0.0)\n",
      "\t--> Clustering coefficient : 0.17053377503758754 \\ \n",
      "\t--> Giant component size : 48\n",
      ">>> Combination n°10 with weights (0.0, 0.125, 0.0, 0.875)\n",
      "\t--> Clustering coefficient : 0.04553216348969004 \\ \n",
      "\t--> Giant component size : 64\n",
      ">>> Combination n°11 with weights (0.0, 0.125, 0.125, 0.75)\n",
      "\t--> Clustering coefficient : 0.0523034545208187 \\ \n",
      "\t--> Giant component size : 32\n",
      ">>> Combination n°12 with weights (0.0, 0.125, 0.25, 0.625)\n",
      "\t--> Clustering coefficient : 0.06729492660160992 \\ \n",
      "\t--> Giant component size : 29\n",
      ">>> Combination n°13 with weights (0.0, 0.125, 0.375, 0.5)\n",
      "\t--> Clustering coefficient : 0.09604278248875378 \\ \n",
      "\t--> Giant component size : 24\n",
      ">>> Combination n°14 with weights (0.0, 0.125, 0.5, 0.375)\n",
      "\t--> Clustering coefficient : 0.12548192680738515 \\ \n",
      "\t--> Giant component size : 54\n",
      ">>> Combination n°15 with weights (0.0, 0.125, 0.625, 0.25)\n",
      "\t--> Clustering coefficient : 0.15099072264471025 \\ \n",
      "\t--> Giant component size : 45\n",
      ">>> Combination n°16 with weights (0.0, 0.125, 0.75, 0.125)\n",
      "\t--> Clustering coefficient : 0.1856932571909472 \\ \n",
      "\t--> Giant component size : 97\n",
      ">>> Combination n°17 with weights (0.0, 0.125, 0.875, 0.0)\n",
      "\t--> Clustering coefficient : 0.20860724379916168 \\ \n",
      "\t--> Giant component size : 454\n",
      ">>> Combination n°18 with weights (0.0, 0.25, 0.0, 0.75)\n",
      "\t--> Clustering coefficient : 0.15224492218322844 \\ \n",
      "\t--> Giant component size : 3659\n",
      ">>> Combination n°19 with weights (0.0, 0.25, 0.125, 0.625)\n",
      "\t--> Clustering coefficient : 0.18411655779688424 \\ \n",
      "\t--> Giant component size : 3794\n",
      ">>> Combination n°20 with weights (0.0, 0.25, 0.25, 0.5)\n",
      "\t--> Clustering coefficient : 0.1965701096843191 \\ \n",
      "\t--> Giant component size : 3753\n",
      ">>> Combination n°21 with weights (0.0, 0.25, 0.375, 0.375)\n",
      "\t--> Clustering coefficient : 0.21095263058458813 \\ \n",
      "\t--> Giant component size : 3768\n",
      ">>> Combination n°22 with weights (0.0, 0.25, 0.5, 0.25)\n",
      "\t--> Clustering coefficient : 0.22283714662052484 \\ \n",
      "\t--> Giant component size : 3822\n",
      ">>> Combination n°23 with weights (0.0, 0.25, 0.625, 0.125)\n",
      "\t--> Clustering coefficient : 0.22673108543797757 \\ \n",
      "\t--> Giant component size : 3924\n",
      ">>> Combination n°24 with weights (0.0, 0.25, 0.75, 0.0)\n",
      "\t--> Clustering coefficient : 0.24374678616181217 \\ \n",
      "\t--> Giant component size : 3670\n",
      ">>> Combination n°25 with weights (0.0, 0.375, 0.0, 0.625)\n",
      "\t--> Clustering coefficient : 0.6895241371398597 \\ \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°26 with weights (0.0, 0.375, 0.125, 0.5)\n",
      "\t--> Clustering coefficient : 0.6906116785487227 \\ \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°27 with weights (0.0, 0.375, 0.25, 0.375)\n",
      "\t--> Clustering coefficient : 0.6912641962142987 \\ \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°28 with weights (0.0, 0.375, 0.375, 0.25)\n",
      "\t--> Clustering coefficient : 0.6910988752084017 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°29 with weights (0.0, 0.375, 0.5, 0.125)\n",
      "\t--> Clustering coefficient : 0.6907748927562175 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°30 with weights (0.0, 0.375, 0.625, 0.0)\n",
      "\t--> Clustering coefficient : 0.6901129733177127 \\ \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°31 with weights (0.0, 0.5, 0.0, 0.5)\n",
      "\t--> Clustering coefficient : 0.6229911484686901 \\ \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°32 with weights (0.0, 0.5, 0.125, 0.375)\n",
      "\t--> Clustering coefficient : 0.6234725667557108 \\ \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°33 with weights (0.0, 0.5, 0.25, 0.25)\n",
      "\t--> Clustering coefficient : 0.623706792719991 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°34 with weights (0.0, 0.5, 0.375, 0.125)\n",
      "\t--> Clustering coefficient : 0.6234362472874648 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°35 with weights (0.0, 0.5, 0.5, 0.0)\n",
      "\t--> Clustering coefficient : 0.6231461794570112 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°36 with weights (0.0, 0.625, 0.0, 0.375)\n",
      "\t--> Clustering coefficient : 0.6230139333093195 \\ \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°37 with weights (0.0, 0.625, 0.125, 0.25)\n",
      "\t--> Clustering coefficient : 0.623453518233812 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°38 with weights (0.0, 0.625, 0.25, 0.125)\n",
      "\t--> Clustering coefficient : 0.6237063816902055 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°39 with weights (0.0, 0.625, 0.375, 0.0)\n",
      "\t--> Clustering coefficient : 0.623545854995267 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°40 with weights (0.0, 0.75, 0.0, 0.25)\n",
      "\t--> Clustering coefficient : 0.6295555584223761 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°41 with weights (0.0, 0.75, 0.125, 0.125)\n",
      "\t--> Clustering coefficient : 0.6296508400602759 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°42 with weights (0.0, 0.75, 0.25, 0.0)\n",
      "\t--> Clustering coefficient : 0.6297521921052878 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°43 with weights (0.0, 0.875, 0.0, 0.125)\n",
      "\t--> Clustering coefficient : 0.6453322738909865 \\ \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°44 with weights (0.0, 0.875, 0.125, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch way\n",
    "names = list(sim_mat.keys()) # name of similarity matrix\n",
    "mat_dim = sim_mat['keywords'].shape # shape of them\n",
    "prune_threshold = 0.25 # threhold to prune the summed adjacency matrix\n",
    "\n",
    "weight_range = [np.arange(0.125, 1.01, 0.125), \\\n",
    "                          np.arange(0.125, 1.01, 0.125), \\\n",
    "                          np.arange(0.125, 1.01, 0.125), \\\n",
    "                          np.arange(0.125, 1.01, 0.125)] # Range of weight to test\n",
    "weights_list = [] # to store the output\n",
    "clustering_coef = [] # to store output\n",
    "eigenvals = [] # to store the eigenvalues\n",
    "giant_comp_size = []\n",
    "\n",
    "j=0\n",
    "for w in itertools.product(*weight_range): # iterate over all combination of weights\n",
    "    if sum(w) == 1: # if the weight sum up to 1 \n",
    "        j+=1\n",
    "        print(f'>>> Combination n°{j} with weights {w}')\n",
    "        weights_list.append(w)\n",
    "        adj_mat = np.zeros(mat_dim)\n",
    "        for wi, name in zip(w, names): # sum the similarity matrices\n",
    "            adj_mat += wi*sim_mat[name].values\n",
    "\n",
    "        G=nx.from_numpy_matrix(np.where(adj_mat < prune_threshold, 0, adj_mat)) # prune adjacency matrix\n",
    "        C = nx.average_clustering(G) # compute the average clustering coefficient\n",
    "        n_gc = max(nx.connected_component_subgraphs(G), key=len).number_of_nodes()\n",
    "        eigenvals.append(nx.linalg.spectrum.normalized_laplacian_spectrum(G))\n",
    "        giant_comp_size.append(n_gc)\n",
    "        \n",
    "        print(f'\\t--> Clustering coefficient : {C} \\n\\t--> Giant component size : {n_gc}')\n",
    "        clustering_coef.append(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the best combination of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = np.argmin(np.array(eigenvals).sum(axis=1)) # where the sum of eigenvalues is minimal\n",
    "#idx = np.argmax(np.array(clustering_coef))\n",
    "idx = np.argmax(np.array(giant_comp_size))\n",
    "weights = weights_list[idx]\n",
    "\n",
    "final_adjacency_mat= np.zeros(mat_dim)\n",
    "for wi, name in zip(weights, names): # sum the similarity matrices\n",
    "    final_adjacency_mat+= wi*sim_mat[name].values\n",
    "    \n",
    "final_adjacency_mat = np.where(final_adjacency_mat < prune_threshold, 0, final_adjacency_mat)\n",
    "weight_dict = {'names':names, 'weights':weights}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the adjacency matrix and the weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Data_path+'Adjacency_matrix.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_adjacency_mat, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Adjacency matrix saved at '+Data_path+'Adjacency_matrix.pickle')\n",
    "    \n",
    "with open(Data_path+'Adjacency_weights.pickle', 'wb') as handle:\n",
    "    pickle.dump(weight_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Adjacency weights saved at '+Data_path+'Adjacency_weights.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
