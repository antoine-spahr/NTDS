{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the similarity matrices and the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading keywords similarity matrix with shape (4803, 4803)\n",
      ">>> Loading genre similarity matrix with shape (4803, 4803)\n",
      ">>> Loading crew similarity matrix with shape (4803, 4803)\n",
      ">>> Loading cast similarity matrix with shape (4803, 4803)\n"
     ]
    }
   ],
   "source": [
    "Data_path = 'Data/'\n",
    "\n",
    "sim_mat = {}\n",
    "names = ['keywords', 'genre', 'crew', 'cast']\n",
    "for name in names:\n",
    "    with open(Data_path+'csim_'+name, 'rb') as src:\n",
    "        sim_mat[name] = pickle.load(src)\n",
    "        print(f'>>> Loading {name} similarity matrix with shape {sim_mat[name].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 1** Combine the 4 similarity matrices equitably (**to be optimized**) and pruned those with a similarity below 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple way\n",
    "adj_mat = np.zeros(sim_mat['keywords'].shape)\n",
    "for wi, name in zip([0.25, 0.25, 0.25, 0.25], names):\n",
    "     adj_mat += wi*sim_mat[name].values\n",
    "final_adjacency_mat = np.where(adj_mat < 0.25, 0, adj_mat)\n",
    "weight_dict = {'names':names, 'weights':[0.25, 0.25, 0.25, 0.25]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 2** Grid search the best combination of weights (weights that sum up to 1) and then prune the adjacency matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Combination n°1 with weights (0.125, 0.125, 0.125, 0.625)\n",
      "\t--> Clustering coefficient : 0.0497875005370321 \n",
      "\t--> Giant component size : 19\n",
      ">>> Combination n°2 with weights (0.125, 0.125, 0.25, 0.5)\n",
      "\t--> Clustering coefficient : 0.06932720621040421 \n",
      "\t--> Giant component size : 20\n",
      ">>> Combination n°3 with weights (0.125, 0.125, 0.375, 0.375)\n",
      "\t--> Clustering coefficient : 0.09436658490374918 \n",
      "\t--> Giant component size : 24\n",
      ">>> Combination n°4 with weights (0.125, 0.125, 0.5, 0.25)\n",
      "\t--> Clustering coefficient : 0.12299657238574094 \n",
      "\t--> Giant component size : 33\n",
      ">>> Combination n°5 with weights (0.125, 0.125, 0.625, 0.125)\n",
      "\t--> Clustering coefficient : 0.15422879052267055 \n",
      "\t--> Giant component size : 45\n",
      ">>> Combination n°6 with weights (0.125, 0.25, 0.125, 0.5)\n",
      "\t--> Clustering coefficient : 0.2854848597415816 \n",
      "\t--> Giant component size : 4128\n",
      ">>> Combination n°7 with weights (0.125, 0.25, 0.25, 0.375)\n",
      "\t--> Clustering coefficient : 0.29668934374189415 \n",
      "\t--> Giant component size : 4114\n",
      ">>> Combination n°8 with weights (0.125, 0.25, 0.375, 0.25)\n",
      "\t--> Clustering coefficient : 0.2996956692257036 \n",
      "\t--> Giant component size : 4161\n",
      ">>> Combination n°9 with weights (0.125, 0.25, 0.5, 0.125)\n",
      "\t--> Clustering coefficient : 0.3005889489042148 \n",
      "\t--> Giant component size : 4212\n",
      ">>> Combination n°10 with weights (0.125, 0.375, 0.125, 0.375)\n",
      "\t--> Clustering coefficient : 0.6831022112793694 \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°11 with weights (0.125, 0.375, 0.25, 0.25)\n",
      "\t--> Clustering coefficient : 0.6833745255393402 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°12 with weights (0.125, 0.375, 0.375, 0.125)\n",
      "\t--> Clustering coefficient : 0.6830171436023187 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°13 with weights (0.125, 0.5, 0.125, 0.25)\n",
      "\t--> Clustering coefficient : 0.6226073622766022 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°14 with weights (0.125, 0.5, 0.25, 0.125)\n",
      "\t--> Clustering coefficient : 0.6225689404161416 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°15 with weights (0.125, 0.625, 0.125, 0.125)\n",
      "\t--> Clustering coefficient : 0.6217204246919477 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°16 with weights (0.25, 0.125, 0.125, 0.5)\n",
      "\t--> Clustering coefficient : 0.07769266750985747 \n",
      "\t--> Giant component size : 245\n",
      ">>> Combination n°17 with weights (0.25, 0.125, 0.25, 0.375)\n",
      "\t--> Clustering coefficient : 0.0933924645297923 \n",
      "\t--> Giant component size : 281\n",
      ">>> Combination n°18 with weights (0.25, 0.125, 0.375, 0.25)\n",
      "\t--> Clustering coefficient : 0.11882349615292996 \n",
      "\t--> Giant component size : 327\n",
      ">>> Combination n°19 with weights (0.25, 0.125, 0.5, 0.125)\n",
      "\t--> Clustering coefficient : 0.14176707810711228 \n",
      "\t--> Giant component size : 437\n",
      ">>> Combination n°20 with weights (0.25, 0.25, 0.125, 0.375)\n",
      "\t--> Clustering coefficient : 0.29703443467255114 \n",
      "\t--> Giant component size : 4254\n",
      ">>> Combination n°21 with weights (0.25, 0.25, 0.25, 0.25)\n",
      "\t--> Clustering coefficient : 0.3023049451648033 \n",
      "\t--> Giant component size : 4270\n",
      ">>> Combination n°22 with weights (0.25, 0.25, 0.375, 0.125)\n",
      "\t--> Clustering coefficient : 0.30010949178403645 \n",
      "\t--> Giant component size : 4316\n",
      ">>> Combination n°23 with weights (0.25, 0.375, 0.125, 0.25)\n",
      "\t--> Clustering coefficient : 0.6761701758477169 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°24 with weights (0.25, 0.375, 0.25, 0.125)\n",
      "\t--> Clustering coefficient : 0.6761498595125613 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°25 with weights (0.25, 0.5, 0.125, 0.125)\n",
      "\t--> Clustering coefficient : 0.6204325093271063 \n",
      "\t--> Giant component size : 4775\n",
      ">>> Combination n°26 with weights (0.375, 0.125, 0.125, 0.375)\n",
      "\t--> Clustering coefficient : 0.10345002368991607 \n",
      "\t--> Giant component size : 710\n",
      ">>> Combination n°27 with weights (0.375, 0.125, 0.25, 0.25)\n",
      "\t--> Clustering coefficient : 0.11879691928505333 \n",
      "\t--> Giant component size : 783\n",
      ">>> Combination n°28 with weights (0.375, 0.125, 0.375, 0.125)\n",
      "\t--> Clustering coefficient : 0.13652702362217795 \n",
      "\t--> Giant component size : 925\n",
      ">>> Combination n°29 with weights (0.375, 0.25, 0.125, 0.25)\n",
      "\t--> Clustering coefficient : 0.3048182872866742 \n",
      "\t--> Giant component size : 4392\n",
      ">>> Combination n°30 with weights (0.375, 0.25, 0.25, 0.125)\n",
      "\t--> Clustering coefficient : 0.30425361770634884 \n",
      "\t--> Giant component size : 4404\n",
      ">>> Combination n°31 with weights (0.375, 0.375, 0.125, 0.125)\n",
      "\t--> Clustering coefficient : 0.6671424293452995 \n",
      "\t--> Giant component size : 4776\n",
      ">>> Combination n°32 with weights (0.5, 0.125, 0.125, 0.25)\n",
      "\t--> Clustering coefficient : 0.14651512929366936 \n",
      "\t--> Giant component size : 1528\n",
      ">>> Combination n°33 with weights (0.5, 0.125, 0.25, 0.125)\n",
      "\t--> Clustering coefficient : 0.15543585006272356 \n",
      "\t--> Giant component size : 1640\n",
      ">>> Combination n°34 with weights (0.5, 0.25, 0.125, 0.125)\n",
      "\t--> Clustering coefficient : 0.30579003417683603 \n",
      "\t--> Giant component size : 4471\n",
      ">>> Combination n°35 with weights (0.625, 0.125, 0.125, 0.125)\n",
      "\t--> Clustering coefficient : 0.19957760433316962 \n",
      "\t--> Giant component size : 2542\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch way\n",
    "names = list(sim_mat.keys()) # name of similarity matrix\n",
    "mat_dim = sim_mat['keywords'].shape # shape of them\n",
    "prune_threshold = 0.25 # threhold to prune the summed adjacency matrix\n",
    "\n",
    "weight_range = [np.arange(0.125, 1.0, 0.125), \\\n",
    "                          np.arange(0.125, 1.0, 0.125), \\\n",
    "                          np.arange(0.125, 1.0, 0.125), \\\n",
    "                          np.arange(0.125, 1.0, 0.125)] # Range of weight to test\n",
    "weights_list = [] # to store the output\n",
    "clustering_coef = [] # to store output\n",
    "eigenvals = [] # to store the eigenvalues\n",
    "giant_comp_size = []\n",
    "\n",
    "j=0\n",
    "for w in itertools.product(*weight_range): # iterate over all combination of weights\n",
    "    if sum(w) == 1: # if the weight sum up to 1 \n",
    "        j+=1\n",
    "        print(f'>>> Combination n°{j} with weights {w}')\n",
    "        weights_list.append(w)\n",
    "        adj_mat = np.zeros(mat_dim)\n",
    "        for wi, name in zip(w, names): # sum the similarity matrices\n",
    "            adj_mat += wi*sim_mat[name].values\n",
    "\n",
    "        G=nx.from_numpy_matrix(np.where(adj_mat < prune_threshold, 0, adj_mat)) # prune adjacency matrix\n",
    "        C = nx.average_clustering(G) # compute the average clustering coefficient\n",
    "        n_gc = max(nx.connected_component_subgraphs(G), key=len).number_of_nodes()\n",
    "        eigenvals.append(nx.linalg.spectrum.normalized_laplacian_spectrum(G))\n",
    "        giant_comp_size.append(n_gc)\n",
    "        \n",
    "        print(f'\\t--> Clustering coefficient : {C} \\n\\t--> Giant component size : {n_gc}')\n",
    "        clustering_coef.append(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the best combination of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = np.argmin(np.array(eigenvals).sum(axis=1)) # where the sum of eigenvalues is minimal\n",
    "#idx = np.argmax(np.array(clustering_coef))\n",
    "idx = np.argmax(np.array(giant_comp_size))\n",
    "weights = weights_list[idx]\n",
    "\n",
    "final_adjacency_mat= np.zeros(mat_dim)\n",
    "for wi, name in zip(weights, names): # sum the similarity matrices\n",
    "    final_adjacency_mat+= wi*sim_mat[name].values\n",
    "    \n",
    "final_adjacency_mat = np.where(final_adjacency_mat < prune_threshold, 0, final_adjacency_mat)\n",
    "weight_dict = {'names':names, 'weights':weights}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the adjacency matrix and the weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Data_path+'Adjacency_matrix.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_adjacency_mat, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Adjacency matrix saved at '+Data_path+'Adjacency_matrix.pickle')\n",
    "    \n",
    "with open(Data_path+'Adjacency_weights.pickle', 'wb') as handle:\n",
    "    pickle.dump(weight_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Adjacency weights saved at '+Data_path+'Adjacency_weights.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
